{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMayueZL7bHZt8Q0x6TSbcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuriEvan/ADALL_github/blob/main/LLM_7thJan26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrFdjzsVYh83",
        "outputId": "99b5e620-c4cb-4313-bc41-e23f768955d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm),sepal width (cm),petal length (cm),petal width (cm),species\n",
            "5.1,3.5,1.4,0.2,setosa\n",
            "4.9,3.0,1.4,0.2,setosa\n",
            "4.7,3.2,1.3,0.2,setosa\n",
            "4.6,3.1,1.5,0.2,setosa\n",
            "5.0,3.6,1.4,0.2,setosa\n",
            "5.4,3.9,1.7,0.4,setosa\n",
            "4.6,3.4,1.4,0.3,setosa\n",
            "5.0,3.4,1.5,0.2,setosa\n",
            "4.4,2.9,1.4,0.2,setosa\n",
            "4.9,3.1,1.5,0.1,setosa\n",
            "\n",
            "The Iris flower dataset is a classic example used for classification tasks in machine learning. It contains 150 samples of iris flowers, each described by 4 features and categorized into one of 3 species: setosa, versicolor, and virginica.\n",
            "\n",
            "### Dataset Overview\n",
            "1. **Features**:\n",
            "   - Sepal Length (cm)\n",
            "   - Sepal Width (cm)\n",
            "   - Petal Length (cm)\n",
            "   - Petal Width (cm)\n",
            "\n",
            "2. **Target Classes**:\n",
            "   - Setosa\n",
            "   - Versicolor\n",
            "   - Virginica\n",
            "\n",
            "### First Steps in Analysis\n",
            "\n",
            "1. **Data Loading**: Load the dataset into a suitable data structure, like a Pandas DataFrame.\n",
            "2. **Data Inspection**: Check for any missing values or inconsistencies.\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "# Load the dataset\n",
            "data = pd.read_csv('path_to_iris_dataset.csv')\n",
            "\n",
            "# Inspect the first few rows\n",
            "print(data.head(10))\n",
            "\n",
            "# Check for missing values\n",
            "print(data.isnull().sum())\n",
            "```\n",
            "\n",
            "### Exploratory Data Analysis (EDA)\n",
            "- **Visualization**: Use plots (scatter plots, pair plots, box plots) to visualize the relationships between features and classes.\n",
            "- **Statistical Summary**: Obtain statistical measures (mean, median, standard deviation) to understand the distribution of the features.\n",
            "\n",
            "```python\n",
            "import seaborn as sns\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Pair plot for visualizing relationships\n",
            "sns.pairplot(data, hue='species')\n",
            "\n",
            "# Show the plot\n",
            "plt.show()\n",
            "\n",
            "# Statistical summary\n",
            "print(data.describe())\n",
            "```\n",
            "\n",
            "### Preprocessing\n",
            "- **Label Encoding**: Convert the species names to numeric labels if needed for classification algorithms.\n",
            "- **Train-Test Split**: Split the dataset into training and testing sets.\n",
            "\n",
            "```python\n",
            "from sklearn.model_selection import train_test_split\n",
            "from sklearn.preprocessing import LabelEncoder\n",
            "\n",
            "# Encode species labels\n",
            "label_encoder = LabelEncoder()\n",
            "data['species'] = label_encoder.fit_transform(data['species'])\n",
            "\n",
            "# Splitting data into features and target variable\n",
            "X = data.drop('species', axis=1)\n",
            "y = data['species']\n",
            "\n",
            "# Train-test split\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
            "```\n",
            "\n",
            "### Classification Model\n",
            "For classification in this dataset, you could use various algorithms: Logistic Regression, Decision Trees, Random Forest, Support Vector Machines, etc. Hereâ€™s how you might implement a simple logistic regression:\n",
            "\n",
            "```python\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.metrics import confusion_matrix, classification_report\n",
            "\n",
            "# Initialize logistic regression model\n",
            "model = LogisticRegression()\n",
            "\n",
            "# Fit the model\n",
            "model.fit(X_train, y_train)\n",
            "\n",
            "# Predict on test data\n",
            "y_pred = model.predict(X_test)\n",
            "\n",
            "# Evaluate the model\n",
            "print(confusion_matrix(y_test, y_pred))\n",
            "print(classification_report(y_test, y_pred))\n",
            "```\n",
            "\n",
            "### Conclusion\n",
            "After evaluating the model, you can further refine it by tuning hyperparameters or exploring more complex algorithms. You can also look into feature importance and different evaluation metrics to better understand model performance.\n",
            "\n",
            "If you need more specific analyses or help with any part of this process, let me know!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load key from Google Colab Secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "client = OpenAI(\n",
        "# This is the default and can be omitted\n",
        "api_key=api_key,\n",
        ")\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "# Add target column (species)\n",
        "df['species'] = iris.target_names[iris.target]\n",
        "\n",
        "# Convert the first few rows to a string to send to OpenAI\n",
        "data_preview = df.head(10).to_csv(index=False)\n",
        "print(data_preview)\n",
        "\n",
        "response = client.responses.create(\n",
        "model=\"gpt-4o-mini\",\n",
        "instructions=\"You are an expert data scientist with extensive knowledge of predictive analysis and linear regression.\",\n",
        "input=f\"Dataset: Iris flower classification (150 samples, 4 features, 3 classes)\\nHere are the first 10 rows of the dataset:\\n{data_preview}]\",\n",
        ")\n",
        "print(response.output_text)"
      ]
    }
  ]
}